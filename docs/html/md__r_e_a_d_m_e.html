<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>EXONA: Evolutionary eXploration of Neural Architectures: Getting Started and Prerequisites</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">EXONA: Evolutionary eXploration of Neural Architectures
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Getting Started and Prerequisites </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>EXONA has been developed to compile using CMake, which should be installed before attempting to compile. To use the MPI version, a version of MPI (such as OpenMPI) should be installed. <a class="el" href="class_e_x_a_c_t.html">EXACT</a> currently requires libtiff and libpng The <a class="el" href="class_e_x_a_c_t.html">EXACT</a> algorithm can also checkpoint to a database, however this is not required. To enable this I recommend installing libmysql-dev via apt-get on Linux systems, or mysql via <a href="https://brew.sh">homebrew</a> on OSX. Other than that, EXACT/EXALT/EXAMM has no prerequesites other than c++11 compatible compiler.</p>
<p>If you are using OSX, to set up the environment:</p>
<div class="fragment"><div class="line">$ brew install cmake</div>
<div class="line">$ brew install mysql</div>
<div class="line">$ xcode-select --install</div>
</div><!-- fragment --><p>To build:</p>
<div class="fragment"><div class="line">~/exact $ mkdir build</div>
<div class="line">~/exact $ cd build</div>
<div class="line">~/exact/build $ cmake ..</div>
<div class="line">~/exact/build $ make</div>
</div><!-- fragment --><p>You may also want to have graphviz installed so you can generate images of the evolved neural networks. EXACT/EXALT/EXAMM will write out evolved genomes in a .gv (graphviz) format for this. For example, can generate a pdf from a gv file (assuming graphviz is installed with):</p>
<div class="fragment"><div class="line">$ dot -Tpdf genome.gv -o genome.pdf</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md1"></a>
EXAMM: Evolutionary eXploration of Augmenting Memory Models and EXALT: Evolutionary eXploration of Augmenting LSTM Topologies</h1>
<p>Source code for EXALT/EXAMM can be found in the rnn subdirectory. EXALT has been enhanced with the ability to utilize more recurrent memory cells and has been renamed <a class="el" href="class_e_x_a_m_m.html">EXAMM</a>. The memory cells currently implemented are Delta-RNN, GRU, LSTM, MGU, and UGRNNs. Some example time series data has been provided as part of two publications on EXALT and <a class="el" href="class_e_x_a_m_m.html">EXAMM</a>, which also provide implementation details:</p>
<ol type="1">
<li>Alex Ororbia, AbdElRahman ElSaid, and Travis Desell. <b><a href="https://dl.acm.org/citation.cfm?id=3321795">Investigating Recurrent Neural Network Memory Structures using Neuro-Evolution</a>.</b> <em>The Genetic and Evolutionary Computation Conference (GECCO 2019).</em> Prague, Czech Republic. July 8-12, 2019.</li>
<li>AbdElRahman ElSaid, Steven Benson, Shuchita Patwardhan, David Stadem and Travis Desell. <b><a href="https://link.springer.com/chapter/10.1007/978-3-030-16692-2_33">Evolving Recurrent Neural Networks for Time Series Data Prediction of Coal Plant Parameters</a>.</b> <em>The 22nd International Conference on the Applications of Evolutionary Computation (EvoStar: EvoApps 2019).</em> Leipzig, Germany. April 24-26, 2019.</li>
</ol>
<p>These datasets can be found in the <em>datasets</em> directory, and provide example CSV files which you can use with <a class="el" href="class_e_x_a_m_m.html">EXAMM</a>. <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> can be run in two different ways, a multithreaded version:</p>
<div class="fragment"><div class="line">./multithreaded/examm_mt --number_threads 9 --training_filenames ../datasets/2018_coal/burner_[0-9].csv --test_filenames ../datasets/2018_coal/burner_1[0-1].csv --time_offset 1 --input_parameter_names Conditioner_Inlet_Temp Conditioner_Outlet_Temp Coal_Feeder_Rate Primary_Air_Flow Primary_Air_Split System_Secondary_Air_Flow_Total Secondary_Air_Flow Secondary_Air_Split Tertiary_Air_Split Total_Comb_Air_Flow Supp_Fuel_Flow Main_Flm_Int --output_parameter_names Main_Flm_Int --number_islands 10 --population_size 10 --max_genomes 2000 --bp_iterations 10 --output_directory &quot;./test_output&quot; --possible_node_types simple UGRNN MGU GRU delta LSTM --std_message_level INFO --file_message_level INFO</div>
</div><!-- fragment --><p>And a parallel version using MPI:</p>
<div class="fragment"><div class="line">~/exact/build/ $ mpirun -np 9 ./mpi/examm_mpi --training_filenames ../datasets/2018_coal/burner_[0-9].csv --test_filenames ../datasets/2018_coal/burner_1[0-1].csv --time_offset 1 --input_parameter_names Conditioner_Inlet_Temp Conditioner_Outlet_Temp Coal_Feeder_Rate Primary_Air_Flow Primary_Air_Split System_Secondary_Air_Flow_Total Secondary_Air_Flow Secondary_Air_Split Tertiary_Air_Split Total_Comb_Air_Flow Supp_Fuel_Flow Main_Flm_Int --output_parameter_names Main_Flm_Int --number_islands 10 --population_size 10 --max_genomes 2000 --bp_iterations 10 --output_directory &quot;./test_output&quot; --possible_node_types simple UGRNN MGU GRU delta LSTM --std_message_level INFO --file_message_level INFO</div>
</div><!-- fragment --><p>Which will run <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> with 9 threads or 9 processes, respectively. Note that <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> uses one thread/process as the master and this typically just waits on the results of backprop so you if you have 8 processors/cores available you can usually run <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> with 9 processes/threads for better performance. A performance log of <a class="el" href="class_r_n_n.html">RNN</a> fitnesses will be exported into fitness_log.csv, as well as the best found RNNs into the specified output directory, in this case *./test_output*. You can control the level of message logging for standard output with <em>&ndash;std_message_level</em> (options are NONE, FATAL, ERROR, WARNING, INFO, DEBUG, TRACE and ALL) and message logging to files (which will be placed in the output directory) with <em>&ndash;file_message_level</em>. Separate logging files will be made for each thread/process.</p>
<p>The aviation data can be run similarly, however it the data should be normalized first (which can be done with the <em>&ndash;normalize</em> command line parameter), e.g.:</p>
<div class="fragment"><div class="line">./multithreaded/examm_mt --number_threads 9 --training_filenames ../datasets/2018_ngafid/flight_[0-7].csv --test_filenames ../datasets/2018_ngafid/flight_[8-9].csv --time_offset 1 --input_parameter_names &quot;AltAGL&quot; &quot;E1 CHT1&quot; &quot;E1 CHT2&quot; &quot;E1 CHT3&quot; &quot;E1 CHT4&quot; &quot;E1 EGT1&quot; &quot;E1 EGT2&quot; &quot;E1 EGT3&quot; &quot;E1 EGT4&quot; &quot;E1 OilP&quot; &quot;E1 OilT&quot; &quot;E1 RPM&quot; &quot;FQtyL&quot; &quot;FQtyR&quot; &quot;GndSpd&quot; &quot;IAS&quot; &quot;LatAc&quot; &quot;NormAc&quot; &quot;OAT&quot; &quot;Pitch&quot; &quot;Roll&quot; &quot;TAS&quot; &quot;volt1&quot; &quot;volt2&quot; &quot;VSpd&quot; &quot;VSpdG&quot; --output_parameter_names Pitch --number_islands 10 --population_size 10 --max_genomes 2000 --bp_iterations 10 --output_directory &quot;./test_output&quot; --possible_node_types simple UGRNN MGU GRU delta LSTM --normalize --std_message_level INFO --file_message_level INFO</div>
</div><!-- fragment --><p>The <em>&ndash;time_offset</em> parameter specifies how many time steps in the future <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> should predict for the output parameter(s). The <em>&ndash;number_islands</em> is the number of islands of populations that <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> will use, and the <em>&ndash;population_size</em> parameter specifies how many individuals/genomes are in each island. The <em>&ndash;bp_iterations</em> specifies how many epochs/iterations backpropagation should be run for each generated <a class="el" href="class_r_n_n.html">RNN</a> genome.</p>
<p>The</p>
<h1><a class="anchor" id="autotoc_md2"></a>
EXACT: Evolutionary Exploration of Augmenting Convolutional Topologies</h1>
<p>This repository provides source code for the Evolutionary Exploration of Augmenting Convolutional Topologies algorithm. This algorithm progressively evolves convolutional neural networks for image classification problems. The algorithm is asychronous, which allows for easy multithreading and parallelization. Code is provided for running <a class="el" href="class_e_x_a_c_t.html">EXACT</a> as a BOINC volunteer computing project, on a cluster or supercomputer using MPI or on a desktop or laptop using threads.</p>
<p>We've built and run <a class="el" href="class_e_x_a_c_t.html">EXACT</a> on both an Ubuntu Linux high performance computing cluser and OSX laptops and desktops. We have not tried it on Windows. If there are issues with the CMake scripts please let us know and we'll update them.</p>
<p>If you want to set this up on your own BOINC volunteer computing project, we recommend sending us an email as this is a rather complicated process.</p>
<p>For more information on <a class="el" href="class_e_x_a_c_t.html">EXACT</a> please see our following publications:</p>
<ol type="1">
<li>Travis Desell. <b><a href="https://arxiv.org/abs/1811.08286">Accelerating the Evolution of Convolutional Neural Networks with Node-Level Mutations and Epigenetic Weight Initialization</a>.</b> <em>arXiv: Neural and Evolutionary Computing (cs.NE).</em> November, 2018.</li>
<li>Travis Desell. <b><a href="https://ieeexplore.ieee.org/document/8109119">Developing a Volunteer Computing Project to Evolve Convolutional Neural Networks and Their Hyperparameters</a>.</b> <em>The 13th IEEE International Conference on eScience (eScience 2017).</em> Auckland, New Zealand. October 24-27 2017.</li>
</ol>
<h2><a class="anchor" id="autotoc_md3"></a>
Setting up Training and Testing Data</h2>
<p>This version <a class="el" href="class_e_x_a_c_t.html">EXACT</a> is set up to run using the <a href="http://yann.lecun.com/exdb/mnist/">MNIST Handwritten Digits Dataset</a>. However it expects a different data format where the images and labels are combined. You can download the data and convert it as follows:</p>
<div class="fragment"><div class="line">~/exact $ mkdir datasets</div>
<div class="line">~/exact $ cd datasets</div>
<div class="line"> </div>
<div class="line">~/exact/datasets $ wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz</div>
<div class="line">~/exact/datasets $ wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz</div>
<div class="line">~/exact/datasets $ wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz</div>
<div class="line">~/exact/datasets $ wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz</div>
<div class="line"> </div>
<div class="line">~/exact/datasets $ unzip train-images-idx3-ubyte.gz</div>
<div class="line">~/exact/datasets $ unzip train-labels-idx1-ubyte.gz</div>
<div class="line">~/exact/datasets $ unzip t10k-images-idx3-ubyte.gz</div>
<div class="line">~/exact/datasets $ unzip t10k-labels-idx1-ubyte.gz</div>
<div class="line"> </div>
<div class="line">~/exact/datasets $ cd ../build</div>
<div class="line">~/exact/build $ ./image_tools/convert_mnist_data ../datasets/train-images-idx3-ubyte ../datasets/train-labels-idx1-ubyte ../datasets/mnist_training_data.bin 60000</div>
<div class="line">~/exact/build $ ./image_tools/convert_mnist_data ../datasets/t10k-images-idx3-ubyte ../datasets/t10k-labels-idx1-ubyte ../datasets/mnist_testing_data.bin 10000</div>
</div><!-- fragment --><p>You can also split up either the training or test data to add a third dataset of validation images for more robust analysis, e.g., so you can train on one set, use the validation set to determine the best CNNs for <a class="el" href="class_e_x_a_c_t.html">EXACT</a> to keep, and then after the evolution process is completed you can test the best found genome(s) on the test set which has not been seen before. You can split up the MNIST training data into a 50k training set and 10k validation set as follows:</p>
<div class="fragment"><div class="line">~/exact/build/ $ ./image_tools/split_mnist_data ../datasets/train-images-idx3-ubyte ../datasets/train-labels-idx1-ubyte ../datasets/mnist_train_50k.bin ../datasets/mnist_validation_10k.bin 60000 1000</div>
</div><!-- fragment --><p>Where the usage is:</p>
<div class="fragment"><div class="line">./image_tools/split_mnist_data &lt;mnist image file&gt; &lt;mnist label file&gt; &lt;output training file&gt; &lt;output validation file&gt; &lt;expected number of images&gt; &lt;validation images per label&gt;</div>
</div><!-- fragment --><p>So this will take 1000 images of each type from the training data and put them into the specified validation file (<em>mnist_validation_10k.bin</em>) and the rest of the images will be in the training set (<em>mnist_train_50k.bin</em>).</p>
<h2><a class="anchor" id="autotoc_md4"></a>
Running EXACT</h2>
<p>You can then run <a class="el" href="class_e_x_a_c_t.html">EXACT</a> in a similar manner to <a class="el" href="class_e_x_a_m_m.html">EXAMM</a>, either using threads or MPI. For the threaded version:</p>
<div class="fragment"><div class="line">~/exact/build/ $ ./multithreaded/exact_mt --number_threads 9 --padding 2 --training_file ../datasets/mnist_train_50k.bin --validation_file ../datasets/mnist_validation_10k.bin  --testing_file ../datasets/mnist_testing_data.bin --population_size 30 --max_epochs 5 --use_sfmp 1 --use_node_operations 1 --max_genomes 1000 --output_directory ./test_exact --search_name &quot;test&quot; --reset_edges 0 --images_resize 50000</div>
</div><!-- fragment --><p>And for the MPI version:</p>
<div class="fragment"><div class="line">~/exact/build/ $ mpirun -np 9 ./mpi/exact_mpi --padding 2 --training_file ../datasets/mnist_train_50k.bin --validation_file ../datasets/mnist_validation_10k.bin  --testing_file ../datasets/mnist_testing_data.bin --population_size 30 --max_epochs 5 --use_sfmp 1 --use_node_operations 1 --max_genomes 1000 --output_directory ./test_exact --search_name &quot;test&quot; --reset_edges 0 --images_resize 50000</div>
</div><!-- fragment --><p>Which will run <a class="el" href="class_e_x_a_c_t.html">EXACT</a> with 9 threads or processes, respectively. The <em>&ndash;use_sfmp</em> argument turns on or off scaled fractional max pooling (which allows for pooling operations between feature maps of any size), the <em>&ndash;use_node_operations</em> argument turns on or off node level mutations (see the <a class="el" href="class_e_x_a_c_t.html">EXACT</a> and <a class="el" href="class_e_x_a_m_m.html">EXAMM</a> papers), the <em>&ndash;reset_edges</em> parameter turns on or off Lamarckian weight evolution (turning it on will evolve and train networks faster) and the <em>&ndash;images_resize</em> parameter allows <a class="el" href="class_e_x_a_c_t.html">EXACT</a> to train CNNs on a subset of the training data to speed the evolution process (e.g., &ndash;images_resize 5000 would train each CNN on a different subset of 5k images from the training data, as opposed to the full 50k).</p>
<h2><a class="anchor" id="autotoc_md5"></a>
Example Genomes from GECCO 2017</h2>
<p>Our submission to GECCO describes a set of best found genomes for the MNIST handwritten digits dataset. These can be found in the genomes subdirectory of the project. Please checkout the tag for the GECCO paper to use the version of <a class="el" href="class_e_x_a_c_t.html">EXACT</a> these CNN genome files were generated with:</p>
<div class="fragment"><div class="line">git checkout -b exact_gecco gecco_2017</div>
</div><!-- fragment --><p>After compiling this version and setting up the MNIST training and testing data as described in the previous section, these genomes can be run over the training and testing data for validation as follows:</p>
<div class="fragment"><div class="line">~/exact/build/ $ ./tests/evaluate_cnn --training_data ../datasets/mnist_training_data.bin --testing_data ../datasets/mnist_testing_data.bin --genome_file ../genomes/genome_46823</div>
<div class="line">~/exact/build/ $ ./tests/evaluate_cnn --training_data ../datasets/mnist_training_data.bin --testing_data ../datasets/mnist_testing_data.bin --genome_file ../genomes/genome_57302</div>
<div class="line">~/exact/build/ $ ./tests/evaluate_cnn --training_data ../datasets/mnist_training_data.bin --testing_data ../datasets/mnist_testing_data.bin --genome_file ../genomes/genome_59455</div>
<div class="line">~/exact/build/ $ ./tests/evaluate_cnn --training_data ../datasets/mnist_training_data.bin --testing_data ../datasets/mnist_testing_data.bin --genome_file ../genomes/genome_59920</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
